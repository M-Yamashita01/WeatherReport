# Orb 'circleci/aws-cli@0.1.13' resolved to 'circleci/aws-cli@0.1.13'
# Orb 'circleci/aws-ecr@6.2.0' resolved to 'circleci/aws-ecr@6.2.0'
# Orb 'circleci/aws-ecs@1.0.4' resolved to 'circleci/aws-ecs@1.0.4'
version: 2
jobs:
  setup:
    working_directory: ~/WeatherReport
    docker:
    - image: circleci/ruby:2.6.5
    environment:
    - AWS_DEFAULT_OUTPUT: json
    steps:
    - checkout
    - setup_remote_docker
    - attach_workspace:
        at: WeatherReport
    - run:
        name: Install AWS CLI
        command: |
          export PIP=$(which pip pip3 | head -1)
          if [[ -n $PIP ]]; then
            if which sudo > /dev/null; then
              sudo $PIP install awscli --upgrade
            else
              # This installs the AWS CLI to ~/.local/bin. Make sure that ~/.local/bin is in your $PATH.
              $PIP install awscli --upgrade --user
            fi
          elif [[ $(which unzip curl | wc -l) -eq 2 ]]; then
            cd
            curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
            unzip awscli-bundle.zip
            if which sudo > /dev/null; then
              sudo ~/awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
            else
              # This installs the AWS CLI to the default location (~/.local/lib/aws) and create a symbolic link (symlink) at ~/bin/aws. Make sure that ~/bin is in your $PATH.
              awscli-bundle/install -b ~/bin/aws
            fi
            rm -rf awscli-bundle*
            cd -
          else
            echo "Unable to install AWS CLI. Please install pip."
            exit 1
          fi
    - run:
        name: Configure AWS Access Key ID
        command: |
          aws configure set aws_access_key_id \
          $AWS_ACCESS_KEY_ID \
          --profile my-profile-name
    - run:
        name: Configure AWS Secret Access Key
        command: |
          aws configure set aws_secret_access_key \
          $AWS_SECRET_ACCESS_KEY \
          --profile my-profile-name
    - run:
        name: Configure AWS default region
        command: |
          aws configure set region $AWS_REGION \
          --profile my-profile-name
  test:
    working_directory: ~/WeatherReport
    docker:
    - image: circleci/ruby:2.6.5
    steps:
    - checkout
    - run:
        name: change sudo command
        command: |
          if [[ $CIRCLE_SHELL_ENV =~ "localbuild" ]]; then
            echo 'export SUDO_COMMAND=sudo' >> $BASH_ENV
          fi
    - setup_remote_docker
    - restore_cache:
        name: Restore server db-migrate container
        key: docker-{{ .Branch }}--{{ checksum ".circleci/config.yml" }}--{{ checksum "docker-compose.test.yml"}}--{{ checksum "Dockerfile" }}
    - restore_cache:
        name: Restore client container
        key: docker-{{ .Branch }}--{{ checksum ".circleci/config.yml" }}--{{ checksum "docker-compose.test.yml"}}--{{ checksum "Dockerfile.frontend" }}
    - run:
        name: change sudo command
        command: |
          if [[ $CIRCLE_SHELL_ENV =~ "localbuild" ]]; then
            echo 'export SUDO_COMMAND=sudo' >> $BASH_ENV
          fi
    - run:
        name: docker-compose up
        command: |
          set -x
          ${SUDO_COMMAND} docker-compose -f docker-compose.test.yml up --build -d
    - run:
        name: sleep for waiting launch db
        command: |
          sleep 30
    - run:
        name: run tests
        command: |
          mkdir -p /tmp/test-results
          TEST_FILES="$(circleci tests glob 'spec/**/*_spec.rb' | circleci tests split --split-by=timings)"
          ${SUDO_COMMAND} docker-compose -f docker-compose.test.yml exec server bundle exec rspec --format progress \
                                                                --format RspecJunitFormatter \
                                                                --out /tmp/test-results/rspec.xml \
                                                                $TEST_FILES
    - store_test_results:
        path: /tmp/test-results
    - run:
        name: docker-compose down
        command: |
          set -x
          ${SUDO_COMMAND} docker-compose -f docker-compose.test.yml down
    - save_cache:
        name: Save server db-migrate container
        key: docker-{{ .Branch }}--{{ checksum ".circleci/config.yml" }}--{{ checksum "docker-compose.test.yml"}}--{{ checksum "Dockerfile" }}
        paths:
        - ~/WeatherReport/
    - save_cache:
        name: Save client container
        key: docker-{{ .Branch }}--{{ checksum ".circleci/config.yml" }}--{{ checksum "docker-compose.test.yml"}}--{{ checksum "Dockerfile.frontend" }}
        paths:
        - ~/WeatherReport/frontend/
  deploy:
    working_directory: ~/WeatherReport
    docker:
    - image: circleci/ruby:2.6.5
    steps:
    - checkout
    - restore_cache:
        name: Restore server db-migrate container
        key: docker-{{ .Branch }}--{{ checksum ".circleci/config.yml" }}--{{ checksum "docker-compose.test.yml"}}--{{ checksum "Dockerfile" }}
    - restore_cache:
        name: Restore client container
        key: docker-{{ .Branch }}--{{ checksum ".circleci/config.yml" }}--{{ checksum "docker-compose.test.yml"}}--{{ checksum "Dockerfile.frontend" }}
    - setup_remote_docker
    - checkout
    - run:
        name: Install AWS CLI
        command: |
          export PIP=$(which pip pip3 | head -1)
          if [[ -n $PIP ]]; then
            if which sudo > /dev/null; then
              sudo $PIP install awscli --upgrade
            else
              # This installs the AWS CLI to ~/.local/bin. Make sure that ~/.local/bin is in your $PATH.
              $PIP install awscli --upgrade --user
            fi
          elif [[ $(which unzip curl | wc -l) -eq 2 ]]; then
            cd
            curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
            unzip awscli-bundle.zip
            if which sudo > /dev/null; then
              sudo ~/awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
            else
              # This installs the AWS CLI to the default location (~/.local/lib/aws) and create a symbolic link (symlink) at ~/bin/aws. Make sure that ~/bin is in your $PATH.
              awscli-bundle/install -b ~/bin/aws
            fi
            rm -rf awscli-bundle*
            cd -
          else
            echo "Unable to install AWS CLI. Please install pip."
            exit 1
          fi
    - run:
        name: Configure AWS Access Key ID
        command: |
          aws configure set aws_access_key_id \
          $AWS_ACCESS_KEY_ID \
          --profile my-profile-name
    - run:
        name: Configure AWS Secret Access Key
        command: |
          aws configure set aws_secret_access_key \
          $AWS_SECRET_ACCESS_KEY \
          --profile my-profile-name
    - run:
        name: Configure AWS default region
        command: |
          aws configure set region $AWS_REGION \
          --profile my-profile-name
    - run:
        command: |
          # aws ecr get-login returns a login command w/ a temp token
          LOGIN_COMMAND=$(aws ecr get-login --no-include-email --region $AWS_REGION)

          # save it to an env var & use that env var to login
          $LOGIN_COMMAND
        name: Log into Amazon ECR
    - run:
        command: |
          docker build \
             \
            -f Dockerfile.frontend \
            -t $AWS_ECR_ACCOUNT_URL/$AWS_ECR_REPOSITORY:client_latest \
            .
        name: Build docker image
        no_output_timeout: 10m
    - run:
        command: docker push $AWS_ECR_ACCOUNT_URL/$AWS_ECR_REPOSITORY:client_latest
        name: Push image to Amazon ECR
  aws-ecs/deploy-service-update:
    docker:
    - image: circleci/python:3.7.1
    steps:
    - run:
        name: Install AWS CLI
        command: |
          export PIP=$(which pip pip3 | head -1)
          if [[ -n $PIP ]]; then
            if which sudo > /dev/null; then
              sudo $PIP install awscli --upgrade
            else
              # This installs the AWS CLI to ~/.local/bin. Make sure that ~/.local/bin is in your $PATH.
              $PIP install aws --upgrade --user
            fi
          elif [[ $(which unzip curl | wc -l) -eq 2 ]]; then
            cd
            curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
            unzip awscli-bundle.zip
            if which sudo > /dev/null; then
              sudo ~/awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
            else
              # This installs the AWS CLI to the default location (~/.local/lib/aws) and create a symbolic link (symlink) at ~/bin/aws. Make sure that ~/bin is in your $PATH.
              awscli-bundle/install -b ~/bin/aws
            fi
            rm -rf awscli-bundle*
            cd -
          else
            echo "Unable to install AWS CLI. Please install pip."
            exit 1
          fi
    - run:
        name: Configure AWS Access Key ID
        command: |
          aws configure set aws_access_key_id \
          $AWS_ACCESS_KEY_ID \
          --profile default
    - run:
        name: Configure AWS Secret Access Key
        command: |
          aws configure set aws_secret_access_key \
          $AWS_SECRET_ACCESS_KEY \
          --profile default
    - run:
        name: Configure AWS default region
        command: |
          aws configure set region ${AWS_REGION} \
          --profile default
    - run:
        name: Retrieve previous task definition and prepare new task definition values
        command: |
          PREVIOUS_TASK_DEFINITION=$(aws ecs describe-task-definition --task-definition ${MY_APP_PREFIX} --include TAGS)
          CONTAINER_IMAGE_NAME_UPDATES="$(echo container=client_latest,tag=client_latest)"
          CONTAINER_ENV_VAR_UPDATES="$(echo )"

          # Prepare script for updating container definitions
          UPDATE_CONTAINER_DEFS_SCRIPT_FILE=$(mktemp _update_container_defs.py.XXXXXX)
          chmod +x $UPDATE_CONTAINER_DEFS_SCRIPT_FILE
          cat > $UPDATE_CONTAINER_DEFS_SCRIPT_FILE <<-EOF
          from __future__ import absolute_import
          import sys
          import json


          def run(previous_task_definition, container_image_name_updates, container_env_var_updates):
              try:
                  definition = json.loads(previous_task_definition)
                  container_definitions = definition['taskDefinition']['containerDefinitions']
              except:
                  raise Exception('No valid task definition found: ' +
                                  previous_task_definition)

              # Build a map of the original container definitions so that the
              # array index positions can be easily looked up
              container_map = {}
              for index, container_definition in enumerate(container_definitions):
                  env_var_map = {}
                  env_var_definitions = container_definition.get('environment')
                  if env_var_definitions is not None:
                      for env_var_index, env_var_definition in enumerate(env_var_definitions):
                          env_var_map[env_var_definition['name']] = {
                              'index': env_var_index}
                  container_map[container_definition['name']] = {
                      'image': container_definition['image'], 'index': index, 'environment_map': env_var_map}

              # Expected format: container=...,name=...,value=...,container=...,name=...,value=
              try:
                  env_kv_pairs = container_env_var_updates.split(',')
                  for index, kv_pair in enumerate(env_kv_pairs):
                      kv = kv_pair.split('=')
                      key = kv[0].strip()

                      if key == 'container':
                          container_name = kv[1].strip()
                          env_var_name_kv = env_kv_pairs[index+1].split('=')
                          env_var_name = env_var_name_kv[1].strip()
                          env_var_value_kv = env_kv_pairs[index+2].split('=')
                          env_var_value = env_var_value_kv[1].strip()
                          if env_var_name_kv[0].strip() != 'name' or env_var_value_kv[0].strip() != 'value':
                              raise ValueError(
                                  'Environment variable update parameter format is incorrect: ' + container_env_var_updates)

                          container_entry = container_map.get(container_name)
                          if container_entry is None:
                              raise ValueError('The container ' + container_name +
                                               ' is not defined in the existing task definition')
                          container_index = container_entry['index']
                          env_var_entry = container_entry['environment_map'].get(
                              env_var_name)
                          if env_var_entry is None:
                              # The existing container definition did not contain environment variables
                              if container_definitions[container_index].get('environment') is None:
                                  container_definitions[container_index]['environment'] = []
                              # This env var did not exist in the existing container definition
                              container_definitions[container_index]['environment'].append({'name': env_var_name, 'value': env_var_value})
                          else:
                              env_var_index = env_var_entry['index']
                              container_definitions[container_index]['environment'][env_var_index]['value'] = env_var_value
                      elif key and key not in ['container', 'name', 'value']:
                          raise ValueError(
                              'Incorrect key found in environment variable update parameter: ' + key)
              except ValueError as value_error:
                  raise value_error
              except:
                  raise Exception(
                      'Environment variable update parameter could not be processed; please check parameter value: ' + container_env_var_updates)

              # Expected format: container=...,image-and-tag|image|tag=...,container=...,image-and-tag|image|tag=...,
              try:
                  if container_image_name_updates and "container=" not in container_image_name_updates:
                      raise ValueError(
                          'The container parameter is required in the container_image_name_updates variable.')

                  image_kv_pairs = container_image_name_updates.split(',')
                  for index, kv_pair in enumerate(image_kv_pairs):
                      kv = kv_pair.split('=')
                      key = kv[0].strip()
                      if key == 'container':
                          container_name = kv[1].strip()
                          image_kv = image_kv_pairs[index+1].split('=')
                          container_entry = container_map.get(container_name)
                          if container_entry is None:
                              raise ValueError('The container ' + container_name +
                                               ' is not defined in the existing task definition')
                          container_index = container_entry['index']
                          image_specifier_type = image_kv[0].strip()
                          image_value = image_kv[1].strip()
                          if image_specifier_type == 'image-and-tag':
                              container_definitions[container_index]['image'] = image_value
                          else:
                              existing_image_name_tokens = container_entry['image'].split(
                                  ':')
                              if image_specifier_type == 'image':
                                  tag = ''
                                  if len(existing_image_name_tokens) == 2:
                                      tag = ':' + existing_image_name_tokens[1]
                                  container_definitions[container_index]['image'] = image_value + tag
                              elif image_specifier_type == 'tag':
                                  container_definitions[container_index]['image'] = existing_image_name_tokens[0] + \
                                      ':' + image_value
                              else:
                                  raise ValueError(
                                      'Image name update parameter format is incorrect: ' + container_image_name_updates)
                      elif key and key not in ['container', 'image', 'image-and-tag', 'tag']:
                          raise ValueError(
                              'Incorrect key found in image name update parameter: ' + key)

              except ValueError as value_error:
                  raise value_error
              except:
                  raise Exception(
                      'Image name update parameter could not be processed; please check parameter value: ' + container_image_name_updates)
              return json.dumps(container_definitions)


          if __name__ == '__main__':
              try:
                  print(run(sys.argv[1], sys.argv[2], sys.argv[3]))
              except Exception as e:
                  sys.stderr.write(str(e) + "\n")
                  exit(1)

          EOF

          # Prepare container definitions
          CONTAINER_DEFS=$(python $UPDATE_CONTAINER_DEFS_SCRIPT_FILE "$PREVIOUS_TASK_DEFINITION" "$CONTAINER_IMAGE_NAME_UPDATES" "$CONTAINER_ENV_VAR_UPDATES")

          # Escape single quotes from environment variables for BASH_ENV
          CLEANED_CONTAINER_DEFS=$(echo $CONTAINER_DEFS | sed -E "s:':'\\\'':g")

          # Prepare script for getting task definition values
          GET_TASK_DFN_VAL_SCRIPT_FILE=$(mktemp _get_task_def_value.py.XXXXXX)
          chmod +x $GET_TASK_DFN_VAL_SCRIPT_FILE
          cat > $GET_TASK_DFN_VAL_SCRIPT_FILE <<-EOF
          from __future__ import absolute_import
          import sys
          import json


          def run(element_name, task_definition_str):
              try:
                  definition = json.loads(task_definition_str)
                  task_definition = definition['taskDefinition']
              except:
                  raise Exception('No valid task definition found: ' +
                                  task_definition_str)
              str_list_types = ['requiresCompatibilities']
              json_arr_types = ['placementConstraints', 'volumes', 'tags']
              json_obj_types = ['proxyConfiguration']
              if element_name in json_arr_types:
                  output_value = '[]'
              elif element_name in json_obj_types:
                  output_value = '{}'
              else:
                  output_value = ''
              if element_name == 'tags':
                  if element_name in definition:
                      element_value = definition[element_name]
                      output_value = json.dumps(element_value)
              elif element_name in task_definition:
                  element_value = task_definition[element_name]
                  if element_name in str_list_types:
                      output_value = ' '.join(list_item.strip() for list_item in element_value)
                  elif element_name in json_arr_types or element_name in json_obj_types:
                      output_value = json.dumps(element_value)
                  else:
                      output_value = str(element_value)
              return output_value


          if __name__ == '__main__':
              try:
                  print(run(sys.argv[1], sys.argv[2]))
              except Exception as e:
                  sys.stderr.write(str(e) + "\n")
                  exit(1)

          EOF

          # Get other task definition values
          TASK_ROLE=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'taskRoleArn' "$PREVIOUS_TASK_DEFINITION")
          EXECUTION_ROLE=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'executionRoleArn' "$PREVIOUS_TASK_DEFINITION")
          NETWORK_MODE=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'networkMode' "$PREVIOUS_TASK_DEFINITION")
          VOLUMES=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'volumes' "$PREVIOUS_TASK_DEFINITION")
          PLACEMENT_CONSTRAINTS=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'placementConstraints' "$PREVIOUS_TASK_DEFINITION")
          REQ_COMP=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'requiresCompatibilities' "$PREVIOUS_TASK_DEFINITION")
          TASK_CPU=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'cpu' "$PREVIOUS_TASK_DEFINITION")
          TASK_MEMORY=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'memory' "$PREVIOUS_TASK_DEFINITION")
          PID_MODE=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'pidMode' "$PREVIOUS_TASK_DEFINITION")
          IPC_MODE=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'ipcMode' "$PREVIOUS_TASK_DEFINITION")
          TAGS=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'tags' "$PREVIOUS_TASK_DEFINITION")
          PROXY_CONFIGURATION=$(python $GET_TASK_DFN_VAL_SCRIPT_FILE 'proxyConfiguration' "$PREVIOUS_TASK_DEFINITION")

          # Make task definition values available as env variables
          echo "export CCI_ORB_AWS_ECS_TASK_ROLE='${TASK_ROLE}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_EXECUTION_ROLE='${EXECUTION_ROLE}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_NETWORK_MODE='${NETWORK_MODE}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_CONTAINER_DEFS='${CLEANED_CONTAINER_DEFS}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_VOLUMES='${VOLUMES}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_PLACEMENT_CONSTRAINTS='${PLACEMENT_CONSTRAINTS}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_REQ_COMP='${REQ_COMP}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_TASK_CPU='${TASK_CPU}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_TASK_MEMORY='${TASK_MEMORY}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_PID_MODE='${PID_MODE}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_IPC_MODE='${IPC_MODE}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_TAGS='${TAGS}'" >> $BASH_ENV
          echo "export CCI_ORB_AWS_ECS_PROXY_CONFIGURATION='${PROXY_CONFIGURATION}'" >> $BASH_ENV

          rm $UPDATE_CONTAINER_DEFS_SCRIPT_FILE $GET_TASK_DFN_VAL_SCRIPT_FILE
    - run:
        name: Register new task definition
        command: |
          if [ -n "${CCI_ORB_AWS_ECS_TASK_ROLE}" ]; then
              set -- "$@" --task-role-arn "${CCI_ORB_AWS_ECS_TASK_ROLE}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_EXECUTION_ROLE}" ]; then
              set -- "$@" --execution-role-arn "${CCI_ORB_AWS_ECS_EXECUTION_ROLE}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_NETWORK_MODE}" ]; then
              set -- "$@" --network-mode "${CCI_ORB_AWS_ECS_NETWORK_MODE}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_VOLUMES}" ] && [ "${CCI_ORB_AWS_ECS_VOLUMES}" != "[]" ]; then
              set -- "$@" --volumes "${CCI_ORB_AWS_ECS_VOLUMES}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_PLACEMENT_CONSTRAINTS}" ] && [ "${CCI_ORB_AWS_ECS_PLACEMENT_CONSTRAINTS}" != "[]" ]; then
              set -- "$@" --placement-constraints "${CCI_ORB_AWS_ECS_PLACEMENT_CONSTRAINTS}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_REQ_COMP}" ] && [ "${CCI_ORB_AWS_ECS_REQ_COMP}" != "[]" ]; then
              set -- "$@" --requires-compatibilities ${CCI_ORB_AWS_ECS_REQ_COMP}
          fi
          if [ -n "${CCI_ORB_AWS_ECS_TASK_CPU}" ]; then
              set -- "$@" --cpu "${CCI_ORB_AWS_ECS_TASK_CPU}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_TASK_MEMORY}" ]; then
              set -- "$@" --memory "${CCI_ORB_AWS_ECS_TASK_MEMORY}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_PID_MODE}" ]; then
              set -- "$@" --pid-mode "${CCI_ORB_AWS_ECS_PID_MODE}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_IPC_MODE}" ]; then
              set -- "$@" --ipc-mode "${CCI_ORB_AWS_ECS_IPC_MODE}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_TAGS}" ] && [ "${CCI_ORB_AWS_ECS_TAGS}" != "[]" ]; then
              set -- "$@" --tags "${CCI_ORB_AWS_ECS_TAGS}"
          fi
          if [ -n "${CCI_ORB_AWS_ECS_PROXY_CONFIGURATION}" ] && [ "${CCI_ORB_AWS_ECS_PROXY_CONFIGURATION}" != "{}" ]; then
              set -- "$@" --proxy-configuration "${CCI_ORB_AWS_ECS_PROXY_CONFIGURATION}"
          fi
          REVISION=$(aws ecs register-task-definition \
              --family ${MY_APP_PREFIX} \
              --container-definitions "${CCI_ORB_AWS_ECS_CONTAINER_DEFS}" \
              "$@" \
              --output text \
              --query 'taskDefinition.taskDefinitionArn')
          echo "Registered task definition: ${REVISION}"
          echo "export CCI_ORB_AWS_ECS_REGISTERED_TASK_DFN='${REVISION}'" >> $BASH_ENV
    - run:
        name: Update service with registered task definition
        command: |
          DEPLOYMENT_CONTROLLER="$(echo ECS)"

          if [ "${DEPLOYMENT_CONTROLLER}" = "CODE_DEPLOY" ]; then
              DEPLOYED_REVISION="${CCI_ORB_AWS_ECS_REGISTERED_TASK_DFN}"
              DEPLOYMENT_ID=$(aws deploy create-deployment \
                  --application-name "" \
                  --deployment-group-name "" \
                  --revision "{\"revisionType\": \"AppSpecContent\", \"appSpecContent\": {\"content\": \"{\\\"version\\\": 1, \\\"Resources\\\": [{\\\"TargetService\\\": {\\\"Type\\\": \\\"AWS::ECS::Service\\\", \\\"Properties\\\": {\\\"TaskDefinition\\\": \\\"${CCI_ORB_AWS_ECS_REGISTERED_TASK_DFN}\\\", \\\"LoadBalancerInfo\\\": {\\\"ContainerName\\\": \\\"\\\", \\\"ContainerPort\\\": 80}}}}]}\"}}" \
                  --query deploymentId)
              echo "Created CodeDeploy deployment: $DEPLOYMENT_ID"
          else
            SERVICE_NAME="$(echo ${MY_APP_PREFIX})"

            if [ -z "${SERVICE_NAME}" ]; then
                SERVICE_NAME="$(echo ${MY_APP_PREFIX})"
            fi
            if [ "false" == "true" ]; then
                set -- "$@" --force-new-deployment
            fi
            DEPLOYED_REVISION=$(aws ecs update-service \
                --cluster "${MY_APP_PREFIX}" \
                --service "${SERVICE_NAME}" \
                --task-definition "${CCI_ORB_AWS_ECS_REGISTERED_TASK_DFN}" \
                --output text \
                --query service.taskDefinition \
                "$@")
          fi
          echo "export CCI_ORB_AWS_ECS_DEPLOYED_REVISION='${DEPLOYED_REVISION}'" >> $BASH_ENV
workflows:
  setup_and_build:
    jobs:
    - setup
    - test:
        requires:
        - setup
    - deploy:
        filters:
          branches:
            only: release
        requires:
        - test
    - aws-ecs/deploy-service-update:
        filters:
          branches:
            only: release
        requires:
        - deploy
  version: 2
